\chapter{Implementation}

\section{EMC2 board specification}
\section{Raspberry pi}
This section will describe the single board computer that is used for lane detection in this degree project. The chosen board is a Raspberry Pi 3 which is a credit card sized computer. The third generation of the raspberry has seen some major hardware updates compared to earlier versions. The one used in this project has the following specifications:



\begin{table}[H]
\centering
\caption{Raspberry Pi 3 Model B specifications}
\label{my-label}
\begin{tabular}{lllll}
 Model:	&Raspberry Pi 3 Model B  \\
 Operating system:	&Rasbian-Jessie  \\
 Processor:	&ARM Cortex-A53 1.2 GHz 64-bit quad-core  \\
 Hardware Ports:	&40 GPIO pins, 4 USB ports, HDMI port, Ethernet port,\\  &3.5 mm audio jack, Camera interface, Display interface,\\  &Micro SD card slot
\end{tabular}
\end{table}



The main computer in this project is the emc2 board and thus it would be preferred to utilize it for the lane detection as well. But due to no camera drivers available for the emc2 board it would be difficult to manage the image acquisition. A search for other hardware that is more suitable for the task was carried out and the raspberry pi was chosen due to that it is widely used in computer vision projects and its affordable price point.

\subsection{Pi Camera}
The pi camera module has been chosen as image acquisition device for this project. The camera module has a five megapixel image sensor and a maximum resolution of 2952 x 1944 pixels. This camera was chosen due the fact that it is made specifically for the raspberry pi and is very easy to use. The one used has a wide angel lens which maybe is not optimal??






\includepdf[scale=0.8,pages=1,pagecommand=\section{System architecture}]{./img/architecture.pdf}

\section{Lane detection algorithm}
CHANGE ALL THREE PICTURES TO BETTER ONES\\

This chapter will describe the algorithms used for lane detection that have been implemented on the demonstrator of this project. 

The algorithm that has been implemented on the demonstrator so far consist of the following steps:

The lane detection process starts with grabbing a frame from the pi camera and applying a few preprocessing steps to the image. 

The first step is to crop the image to only contain the region of interest (ROI). This is a camera setting that can be predefined so that the camera only grabs the ROI and thus not need to crop it after the frame is grabbed.


Following step is to convert the image to gray scale to prepare it for next coming operations. 



\begin{figure}[H]
  \includegraphics[width=\textwidth]{./img/gray.png}
  \centering
  \caption{Input image converted to grayscale}
  \label{fig:Input image converted to grayscale}
\end{figure}


The gray scale image is the input to the canny edge detection function. As described in the state of the art section the output of the canny function is a thresholded image where all the pixels that are part of edges are set to white and all pixels that are not part of edges are set black.

\begin{figure}[H]
  \includegraphics[width=\textwidth]{./img/edges.png}
  \centering
  \caption{Tresholded image using canny filter}
  \label{fig:Tresholded image using canny filter}
\end{figure}

This thresholded image is used as an input to the hough transform function that is used for line detection. The function works by::(FÃ–RKLARING HOUGH)


The hough transform evaluates the thresholded image by discretizing all


\begin{figure}[H]
  \includegraphics[width=\textwidth]{./img/detected_lines.png}
  \centering
  \caption{Detected lines}
  \label{fig:Detected lines}
\end{figure}


Now the lines are detected and the data  output from the houghlines function need to be handled in some way. 
The algorithm created works by splitting the image into two halves and making the assumption that we have one lane in each of the two halves. By measuring the distance to the line from the center of the image, the error is calculated as $error = xtot - xmid$





\section{Lateral control}
So far all of these steps are all done on the Raspberry Pi thanks to its easy camera implementation and that it supports OpenCV. The error is then sent to the EMC2 board where the lateral control is done using the error from the RPi. A PID controller for the steering servo is developed using z transform.


\section{System ID}
To know how the system will behave when being fed with different PWM values an experimental setup has been developed and many (136) different PWM inputs and steering angle outputs have been measured.


\begin{figure}[H]
  \includegraphics[width=\textwidth]{./img/anglepic.JPG}
  \centering
  \caption{Angle measurement}
  \label{fig:Angle measurement}
\end{figure}


\begin{figure}[H]
  \includegraphics[scale=0.25]{./img/angle.JPG}
  \centering
  \caption{angle}
  \label{fig:angle}
\end{figure}


In the captured images from the camera the angle of the centerline can be calculated using the known x and y values. The x in the picture is calculated as $$x = abs(x1-x2)$$ and y is calculated as $$y=abs(y1-y2)$$ and the angle is obtained using $$tan(\alpha)=\frac{y}{x}$$ and thus $$\alpha = arctan(\frac{y}{x})$$


The mean value of the angle outputs have been calculated and and a first order polynomial have been fitted to the data points using the least squares method. The line calculated is shown in figure  \ref{fig:PWM and angle correlation} and has the equation $$ y=-14.26x + 195.96$$

\begin{figure}[H]
  \includegraphics[width=\textwidth]{./img/PWMPLOT_2.png}
  \centering
  \caption{PWM and angle correlation}
  \label{fig:PWM and angle correlation}
\end{figure}

This line equation is used in the steering control system to evaluate the steering angle compared to the identified line angles.

This is used in combination with the position control to eliminate the deviation from the centerline and thus improve performance of the system.

\section{Implementation and integration with zedboard}
\subsection{Tasks}
What are all the tasks on the zedboard

\begin{figure}[H]
  \includegraphics[width=\textwidth]{./img/sekvensdiagram.png}
  \centering
  \caption{sequence diagram}
  \label{fig:sequence diagram}
\end{figure}
 As shown in figure \ref{fig:sequence diagram} there are currently three tasks scheduled that run on the real time operating system. The task are communication, lateral control and longitudinal control. There will eventually be more tasks implemented including one task to switch to the non critical operating system.

\subsection{Criticality}
EDF, FP ?? which scheduling algorithm should be used? Fixed Priority will be used in the end probably
\subsection{Timing requirements}
Worst case execution time