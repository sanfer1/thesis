\chapter{State of the Art}
In this chapter I will write about the literature study that has been carried out. Things to include in this chapter is: Lane detection in general, Image processing- hough transform etc.. MCS. Misra-c? Information about the board  (EMC2 and zedboard)

\section{SAE Level}
When talking about Advanced Driver Assistance Systems (ADAS) and autonomous vehicles it is important to define what it actually means. SAE International is a professional association and standards developing organization for transport industries. They have developed a new standard for autonomous driving called  "J3016: Taxonomy and Definitions for Terms Related to On-Road Motor Vehicle Automated Driving Systems,”. This standard defines six levels of driving automation, from no automation to full automation. \cite{SAE} \cite{SAEweb}. 

\begin{table}[H]
\centering
\caption{SAE Levels}
\label{SAE Levels}
\begin{tabular}{|l|l|l|ll}
\cline{1-3}
 \textbf{Level} & \textbf{Name} & \textbf{Description}	\\
\cline{1-3}\hline
 0	& No Automation & The human does all the work\\ \cline{1-3}\hline
 1  & Driver Assistance & \pbox{7cm}{The vehicle help out by doing a single task. One example is a cruise control where the car holds a reference speed}\\ \cline{1-3}\hline
 2  & Partial Automation & \pbox{7cm}{The vehicle can help the driver with certain things like maintaining speed, keeping within the lanes, avoiding collisions with other vehicles. Ultimately the driver is responsible and need to be prepared for taking over the control}\\ \cline{1-3}
 3  & Conditional Automation & \pbox{7cm}{The first level that is considered as an automated driving system. In this level the vehicle is able to make decisions as overtaking other vehicles and navigating. In this level humans are only the fall-back option if something fails the vehicle will request the human to intervene }\\ \cline{1-3}
 4	& High Automation & \pbox{7cm}{In level 4, the vehicle is able to operate entirely by it self for the first time, there does not need to be any human behind the wheel as a fall-back. What differs this level from full automation is that it is on a geographically limited area like a center of a town, company area or college campus. }\\ \cline{1-3}
 5	& Full Automation & \pbox{7cm}{Level 5 is where full automated driving is reached. The vehicle can handle all operating modes. There is no steering wheel nor pedals. Just let the vehicle know where you want to go.}\\ \cline{1-3}
\end{tabular}
\end{table}

\section{Lane keeping}
For a human driving may seem like a simple process where two basic tasks are involved. The first is to keep the vehicle and the road and the second to avoid collisions. But in reality driving is not so trivial, a driver need to continuously analyze the road scene and choose and execute the appropriate maneuvers to deal with the current situation. To help the drivers do these tasks Driving Assistance Systems (DAS) have been developed. These systems can help the driver to perceive the blind area in the road for an example. An extension is the Advanced Driving Assistance System (ADAS) Which can perform basic tasks like: Lane following, Lane keeping assistance, Lane departure warning, lateral control, intelligent cruise control, collision warning and ultimately autonomous driving.\\

The main bottleneck in the development of ADAS systems is the perception problem, which has two elements: road and lane perception, and obstacle detection. In this section I will investigate the first element and study what the current state of the art is.\\

Today there are several different sensing modalities used for lane detection. Some examples are monocular vision, stereo vision, LIDAR, IMU data, GPS.\\


Vison is the most prominent research area due to the fact that road signs/markings are made for human vision. Vision sensors provides good position estimation on the road without the need for any other modalities. However, there are situations when vision sensors simply cannot perform well, for example in extreme weather conditions or when driving off-road. In this kind of situations it is possible to use sensor fusion with other sensor modalities to provide a better position estimate, and it is the reason why LIDAR and GPS are important compliments to vision for reaching full autonomous driving.\\




In its basic setting the lane detection problem seems like a simple one. The only thing needed is to detect a host lane and only for a short distance ahead. A simple Hough transform-based algorithm solves the problem in 90\% of highway cases %\citep{•}. 
But the impression that the problem is easy is misleading and building a useful system requires a huge R\& D effort. One of the reasons is the high reliability demands. In order to be useful the system needs to reach very low error rates. The exact amount of false alarms is still a subject of research \cite{BarHillel2014}.
At 15 frames per second, 1 false alarm per hour means only one error in 54,000 frames. \\


One factor that makes ADAS hard to implement on large scale is the large amount of different conditions that has to be taken care of. The main sources for condition diversity are:\\
-Lane and road appearance\\
-image clarity issues\\
-poor visibility conditions\\

\section{Modalities}
In this section the modalities used for road and lane detection will be described more in detail.

\subsection{Monocular vision}
The monocular vision system is frequently used for road and lane detection. It is more simply put one camera mounted on the vehicle. The required resolution can be derived from $N_p = \frac{Cd}{w}$, where $N_p$ is the number of horizontal pixels, $C$ is the camera field of view width in radians. $w$ is the lane mark width in meter \cite{BarHillel2014}.\\
When humans drive we continuously look at the road boundaries, the lane markings and the road texture among other things. These road boundaries are designed so that they should be visible for human drivers in all driving condition. Self driving vehicles that are supposed to share the road with human drivers will therefore most likely have to rely on the same perceptual cues as humans.

\subsection{LIDAR}
Light detection and ranging (LIDAR) is a modality that have been used to a large extent in the development of autonomous vehicles for research purposes. The LIDAR measures the environment around the vehicle in 3D. The LIDAR sends out light pulse and measures the time for it to come back. As it is an active light source it is not dependent of having good natural lighting as with a regular camera. \\

LIDAR sensors can perform well in certain situations for example in rural areas to detect road boundaries, \cite{BarHillel2014} but are not well suited for multilane roads without vision data. As the LIDAR only measures 3D structures it not able to detect road markings, although some research have been done on intensity measurement with LIDAR \cite{huang2009finding} \cite{kammel2008lidar} which would make it possible to detect line markings to some extent. One huge drawback with this modality is that the sensors are still very expensive and thus not yet an alternative for implementation in regular passenger vehicles.

\subsection{Stereo imaging}
Stereo imaging is the use of two cameras instead of one camera in order to obtain 3D information about the surrounding. It is a step in between the monocular vision and the LIDAR as it is much cheaper to implement than LIDAR but generally performs less good in terms of accuracy and reliability.  Also the stereo imaging system generally requires greater processing power and is more prone to errors compared to LIDAR. 


\subsection{GIS, GPS, IMU}



\section{Lateral Control}
Pure pursuit
\section{Convolutional Neural Networks}


\section{Flowchart of image processing}

\begin{figure}[H]
  \includegraphics[scale=0.7]{./img/flow.png}
  \centering
  \caption{Flow chart of a general lane detection system}
  \label{fig:Software architecture of the EMC2 platform}
\end{figure}


\subsection{Road model}
The majority of lane detection system initially propose a model of a road. This model can be both something simple as straight lines or more complex splines. Some researchers make the assumption that the road is two parallel lines in the image, this can be done after an operation called inverse perspective mapping, which produces an bird's-eye view  perspective \cite{bertozzi1998gold}. One other common method is to assume that the lanes have a common vanishing point where the both lanes meet and use that as a reference for the lines in the image \cite{Yenikaya:2013:KVR:2522968.2522970}(Fler referenser).
\subsection{Image acquisition}
The image acquisition typically come from a camera that is mounted in the center of the vehicle.
\subsection{Preprocess}
The preprocess is a step where the image is prepared for the next steps in terms of image resolution, where a lower image resolution is often preferred due to the high computational load that high resolution images bring (KÄLLA). Everything that is not part of the Region of interest (ROI) is often removed. This typically means removing the region above the horizon. Often gray-scale images are preferred over color images due to reduced data load \cite{Yenikaya:2013:KVR:2522968.2522970}. Removal of unwanted disturbances such as shadows are often done in the preprocess. 


Inverse Perspective mapping- Get rid of the perspective effect. 

\subsection{Feature Extraction}
There are several features that can be use for road and lane detection. Color, Texture, Edges

For structured roads with clear line markings the edges are the most common feature used for lane detection. An edge is defined as the gradient of the intensity function \cite{Yenikaya:2013:KVR:2522968.2522970}. The output of an edge based method are candidates for lane boundaries, since edge based methods are able to find where the image brightness changes sharply. There are some well known edge detection methods (Prewitt, Roberts, Sobel), but one method called Canny edge detector stands out and is still, 30 years after it was first developed, considered a state-of-the-art edge detector, some even mean that it is an optimal edge detector algorithm \cite{bhadauria2013comparison}. The next step is usually to do binarization and thinning of the output from the edge detector in order to reduce the thickness of all lines to only one pixel. Hough transform is then applied on the image in order to determine if there is an edge at one certain pixel or not. 


\subsection{Model Fitting}
As mentioned in the road model section, very often a road model is used and fitted to the observed information from the feature extraction section. 

The extracted data from the previous step would typically contain both inliers, i.e. data that can be fitted to a line, and outliers, i.e. data that cannot be fitted onto the same line. (Källa)

Assuming that the extracted data from previous steps contains data that can be fitted to one of the models chosen initially, several different approaches have been proposed for model fitting. (KÄLLA) 
Some researchers use least squares method, which is a 

Other research propose the use of "RANdom SAmple Consensus", known as the RANSAC algorithm (KÄLLOR). This method is stated to be superior to least squares method due to its ability to fit a line to the inliers only, without any influence of the outliers on the result.  


\subsection{Time Integration}
The last step that is important for a reliable lane detection system is to be able to incorporate some knowledge from previous frames 


\section{Use case}
My degree project will be about the perception problem for autonomous vehicles. The group is developing a vehicle platoon where one vehicle drives autonomously around a predefined track and a second vehicle is following the first. Use case number 3 in the safecop project description "Vehicle control loss warning" ties well with my own project. In the safecop project description there is mentioned "The US National Highway Traffic Safety Administration (NHTSA) has estimated that “V2V safety
applications have the potential to address approximately 80\% of crashes for unimpaired drivers”." The idea is to implement obstacle detection on the road and send out a warning to other vehicles in the platoon or close surrounding.

With this use case in mind five requirements have been developed:\\

1. The system should be able to keep a constant speed v while keeping track of the road.\\
2. If any object is detected on the road, the vehicle platoon should do an emergency stop.\\
3. If a vehicle in the platoon sends out a warning to other vehicles in the platoon, they should stop within the time limit of x s. \\
4. \\
5\\